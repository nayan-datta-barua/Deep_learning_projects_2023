{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1yH1rLnPKUBijaHQ2QXdFLoJZs391zpCj",
      "authorship_tag": "ABX9TyNEyWLtc2mMZvb5jOrVrI4O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nayan-datta-barua/Deep_learning_projects_2023/blob/main/Patato_disease_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GbACBy-wD-r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models,layers\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/archive.zip\";"
      ],
      "metadata": {
        "id": "N4nH2dEONcCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root='/content/Potato';"
      ],
      "metadata": {
        "id": "v_AjQQly-rRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size=256\n",
        "batch_size=32\n",
        "chanels=3"
      ],
      "metadata": {
        "id": "Sb0DtBx3eDim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3EpG_aieDls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = tf.keras.preprocessing.image_dataset_from_directory(root,shuffle=True,image_size=(image_size,image_size),batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rae_700bOZ_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.class_names"
      ],
      "metadata": {
        "id": "GulQhTsMoqnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for image_batch,label_batch in df.take(1):   # it counts batch_size() thats means 1 batch = 32 \n",
        "     print(image_batch.shape)\n",
        "     print(label_batch.numpy())\n",
        "     for i in range(12):\n",
        "       ax =plt.subplot(3,4,i+1)\n",
        "       plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "       plt.title(df.class_names[label_batch[i]])\n",
        "       plt.axis(\"off\")\n",
        "      \n",
        "        "
      ],
      "metadata": {
        "id": "VyozWZs3qKX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate dataset traning and test and validation dataset\n",
        "def get_seperate_dataset(ds,train_split=.8,val_split=0.1,test_split=0.1,shuffle=True,shuffle_size=10000):\n",
        "  assert(train_split + val_split + test_split) ==1\n",
        "  ds_size=len(ds)\n",
        "  train_size=int(ds_size*train_split)\n",
        "  val_size=int(ds_size*test_split)\n",
        "\n",
        "  train_ds= ds.take(train_size)\n",
        "  val_ds=ds.skip(train_size).take(val_size)\n",
        "  test_ds = ds.skip(train_size).skip(val_size)\n",
        "\n",
        "\n",
        "  \n",
        "  return train_ds,val_ds,test_ds\n"
      ],
      "metadata": {
        "id": "_IdB7UKjrPd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds,val_ds,test_ds =get_seperate_dataset(df)"
      ],
      "metadata": {
        "id": "ET59ZDU_0BVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))\n",
        "print(len(val_ds))\n",
        "print(len(test_ds))\n"
      ],
      "metadata": {
        "id": "dtMdpoi1M9Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "lqvVwNqmYWUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-biGru4vZvfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(256,256),\n",
        "    layers.experimental.preprocessing.Rescaling(.1/256)\n",
        "])"
      ],
      "metadata": {
        "id": "Z5wrnqj9Z-pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation=tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "JaptbXWzbIHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "input_shape=(batch_size,image_size,image_size,chanels)\n",
        "n_classes=3\n",
        "model=models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(n_classes,activation='softmax'),\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "])\n",
        "model.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "OBO-YiuUbIJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "rSvUD7TmbIO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import metrics\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "pOVmDHY2bISE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "id": "wTT8bFlti8Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2=model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "CqxiwT-0jTMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2"
      ],
      "metadata": {
        "id": "J8-7Mmd8reBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "8emL9T_mreEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ],
      "metadata": {
        "id": "csMk1fgNreKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(50),acc,label=\"Tranning Accuracy\")\n",
        "plt.plot(range(50),val_acc,label=\"validation Accuracy\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"traning and validation accuracy\")\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(50),loss,label=\"Tranning Accuracy\")\n",
        "plt.plot(range(50),val_loss,label=\"validation Accuracy\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.title(\"traning and validation accuracy\")\n"
      ],
      "metadata": {
        "id": "qGOTDuLLsuJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0,1)"
      ],
      "metadata": {
        "id": "OG_75WnojrUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IkNO_TFfyqbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name=df.class_names"
      ],
      "metadata": {
        "id": "EvqLRp0TyqeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch,label_batch in df.take(2):   # it counts batch_size() thats means 1 batch = 32 \n",
        "     first_image=image_batch[0].numpy().astype('uint8')\n",
        "     plt.imshow(first_image)\n",
        "     print(\"actual label:\", class_name[label_batch[0].numpy()])\n",
        "     predict=model.predict(image_batch)\n",
        "     print(\"predict label :\",class_name[np.argmax(predict[0])])"
      ],
      "metadata": {
        "id": "my-XfJxLsKbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,images):\n",
        "  img_array=tf.keras.preprocessing.image.img_to_array(images[i].numpy())\n",
        "  img_array=tf.expand_dims(img_array,0)  # create a batch\n",
        "\n",
        "  prediction=model.predict(img_array)\n",
        "  prediction_class =class_name[np.argmax(prediction[0])]\n",
        "  confidance= round(100 * (np.max(prediction[0])),2)\n",
        "  return prediction_class , confidance"
      ],
      "metadata": {
        "id": "hD3dYXW_sKda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy "
      ],
      "metadata": {
        "id": "u8zvMa8131HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.utils.dataset_utils import labels_to_dataset\n",
        "plt.figure(figsize=(12,15))\n",
        "for images,labels in test_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i].numpy().astype('uint8'))\n",
        "    prediction_class , confidance =predict(model,images)\n",
        "\n",
        "    actual_class =class_name[labels[i]]\n",
        "    plt.title(f\"actual class: {actual_class},\\n Predicted class {prediction_class} ,\\n confidence={confidance}\")\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "IGt0VLBxsKfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9nTW0O2sKib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pDGTDoK9Wyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}